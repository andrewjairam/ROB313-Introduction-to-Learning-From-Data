{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn.neighbors._kd_tree import KDTree\n",
    "import time\n",
    "from data_utils import load_dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([4,4,4,4])\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hyperparameters\n",
    "    - beta\n",
    "    - eta\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Loss function is the 2 norm of ||y - Xw||, which the gradient is:\n",
    "\n",
    "$\\triangledown L(w) = 2X^T(Xw-y)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Algorithm modified from Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x_train, y_train, x_test, w):\n",
    "    # add a dummy one feature to each x_train and  point\n",
    "    # Making X matrices\n",
    "    x_train = np.hstack([np.ones((x_train.shape[0], 1)), x_train])\n",
    "    x_test = np.hstack([np.ones((x_test.shape[0], 1)), x_test])\n",
    "    # print(len(x_train)): Number of datapoints in D plus the dummy feature of all ones (D+1)\n",
    "    # print(len(x_train[0])): The number of features (N)\n",
    "\n",
    "    # Economy SVD\n",
    "    U, sigma, V_t = scipy.linalg.svd(x_train, full_matrices=False, compute_uv=True)\n",
    "    w = V_t.T.dot(U.T.dot(y_train) / np.reshape(sigma, (-1,1))) # -1 to let the program reshape by itself\n",
    "    return x_test.dot(w) # the weighted prediction of test data\n",
    "\n",
    "def lin_reg_loss(x, y, w):\n",
    "    return np.mean(np.square(y - x.dot(w)))\n",
    "\n",
    "    \n",
    "def linear_regression_gradient(x, y, w):\n",
    "    return 2 * x.T.dot(x.dot(w) - y) / len(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full-Batch on pumadyn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "C:\\Users\\Brian\\AppData\\Local\\Temp\\ipykernel_8160\\3178989931.py:36: RuntimeWarning: overflow encountered in square\n",
      "  l = np.mean(np.square(y_train - x_train.dot(w)))\n",
      "C:\\Users\\Brian\\AppData\\Local\\Temp\\ipykernel_8160\\341113367.py:21: RuntimeWarning: overflow encountered in multiply\n",
      "  return 2 * x.T.dot(x.dot(w) - y)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = load_dataset('pumadyn32nm')\n",
    "\n",
    "x_train = np.vstack([x_train, x_valid])\n",
    "y_train = np.vstack([y_train, y_valid])\n",
    "\n",
    "# take the first 1000 points: add in the ones vector x_0\n",
    "x_train = x_train[0:1000]\n",
    "x_train = np.hstack([np.ones((x_train.shape[0], 1)), x_train])\n",
    "y_train = y_train[0:1000]\n",
    "# initialize the weight vector w = 0\n",
    "w = np.zeros([len(x_train[0]), 1])\n",
    "\n",
    "# choose hyperparameters: test on the dataset\n",
    "# k = 1\n",
    "# eta = [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 100]\n",
    "best_eta = None\n",
    "best_eta_RMSE = float('inf')\n",
    "\n",
    "stop = 100000\n",
    "w = np.zeros([len(x_train[0]), 1])\n",
    "\n",
    "# plotting \n",
    "loss = []\n",
    "iterations = [x for x in range(1, stop+1)]\n",
    "\n",
    "\n",
    "for eta in [0.0001, 0.001, 0.01, 0.1, 0.5, 1]:\n",
    "    loss = [] # clear loss array between etas\n",
    "    w = np.zeros([len(x_train[0]), 1])\n",
    "    for k in range(stop):\n",
    "        # gradient descent\n",
    "        g = linear_regression_gradient(x_train, y_train, w)\n",
    "        w = w - eta * g\n",
    "        # loss for this iteration is the average of the l2 loss function\n",
    "        l = lin_reg_loss(x_train, y_train, w)\n",
    "        loss.append(l)\n",
    "\n",
    "    # choose eta using the final weights\n",
    "    if np.sqrt(np.mean(np.square(y_train - x_train.dot(w)))) < best_eta_RMSE:\n",
    "        best_eta_RMSE = np.sqrt(np.mean(np.square(y_train - x_train.dot(w))))\n",
    "        best_eta = eta\n",
    "    plt.figure()\n",
    "    plt.plot(iterations, loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for n in eta:\n",
    "#     k = 1\n",
    "#     # no need to store away weights in training \n",
    "#     w_k = np.zeros([len(x_train[0]), 1])\n",
    "#     w_k_1 = np.zeros([len(x_train[0]), 1])\n",
    "#     # stopping condition: #  10000 iterations\n",
    "#     while k < stop:\n",
    "#         w_k = w_k_1\n",
    "#         # compute gradient of the l2 weight loss function, averaged over N:\n",
    "#         g = 2 * x_train.T.dot(x_train.dot(w_k) - y_train)\n",
    "#         # compute gradient descent update rule: WILL CHANGE DEPENDING ON METHOD\n",
    "#         w_k_1 = w_k - (n/k) * g\n",
    "#         # increment count\n",
    "#         k += 1\n",
    "#     # the prediction is x_train.dot(w_k_1)\n",
    "#     if np.sqrt(np.mean(np.square(y_train - x_train.dot(w_k_1)))) < best_eta_RMSE:\n",
    "#         best_eta_RMSE = np.sqrt(np.mean(np.square(y_train - x_train.dot(w_k_1))))\n",
    "#         best_eta = n\n",
    "#     print(w_k_1 - w_k)\n",
    "\n",
    "# print('best eta:', n, ' with RMSE', best_eta_RMSE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4258d01c5deb34cc98ed3d95cb9eba11316470bc0f05d4178ec7ed26600be0db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
